<!--<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>aiortc Two-Device Demo</title>
  <style>
    body { font-family: system-ui, sans-serif; display:flex; gap:12px; padding:12px; }
    video { width: 48%; background:#000; border-radius:6px; }
  </style>
</head>
<body>
  <video id="local" autoplay muted playsinline></video>
  <video id="remote" autoplay playsinline></video>

  <form action="{{ url_for('set_lang') }}" method="post">
    <label for="language">Choose a language:</label>
    <select name="language" id="language">
      <option value="en">English</option>
      <option value="fr">French</option>
      <option value="hi">Hindi</option>
      <option value="zh">Mandarin Chinese</option>
      <option value="ja">Japanese</option>
      <option value="pt">Portuguese</option>
      <option value="it">Italian</option>
    </select>
  </form>

  <button id="start">Start Recording</button>
  <button id="stop">Stop Recording</button>

<!--<script>
(async () => {
  // Replace nothing here â€” use relative fetch so protocol/host match page (HTTPS)
  const localVideo = document.getElementById("local");
  const remoteVideo = document.getElementById("remote");

  // Use a public STUN to ensure ICE gathering (required for many browsers)
  const pc = new RTCPeerConnection({
    iceServers: [{ urls: "stun:stun.l.google.com:19302" }]
  });

  function uuidv4() {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
      let r = Math.random() * 16 | 0, v = c === 'x' ? r : (r & 0x3 | 0x8);
      return v.toString(16);
    });
  }

  let client_id = uuidv4();


  pc.onicecandidate = (evt) => {
    console.log("ICE candidate event:", evt.candidate);
  };

  pc.onicegatheringstatechange = () => {
    console.log("ICE gathering state:", pc.iceGatheringState);
  };

  pc.onconnectionstatechange = () => {
    console.log("Connection state:", pc.connectionState);
  };

  pc.ontrack = (event) => {
    console.log("REMOTE TRACK:", event.track.kind, "streams:", event.streams);
    // Attach the first incoming stream
    if (event.streams && event.streams[0]) {
      remoteVideo.srcObject = event.streams[0];
      remoteVideo.play().catch(e => console.warn("remoteVideo.play() failed:", e));
    } else {
      // Fallback: create stream from track
      const s = new MediaStream([event.track]);
      remoteVideo.srcObject = s;
      remoteVideo.play().catch(e => console.warn("remoteVideo.play() failed:", e));
    }
  };

  try {
    // 1) Get permission & local stream
    const localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
    localVideo.srcObject = localStream;
    console.log("Got local stream:", localStream);
    document.getElementById("start").onclick = async () => {
      mediaRecorder = new MediaRecorder(localStream);
      mediaRecorder.ondataavailable = event => {
          audioChunks.push(event.data);
      };
      mediaRecorder.start();
    }

    // 2) Add local tracks to connection (senders)
    localStream.getTracks().forEach(t => pc.addTrack(t, localStream));
    console.log("Added local tracks");

    // 3) Create receive transceivers BEFORE creating the offer
    //    This ensures the offer SDP contains recv m-lines so server-forwarded tracks can be received.
    pc.addTransceiver("video", { direction: "recvonly" });
    pc.addTransceiver("audio", { direction: "recvonly" });
    console.log("Added recvonly transceivers");

    // 4) Create offer and set local description
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    console.log("Local description set (initial). Waiting for ICE gathering...");

    // 5) Wait for ICE gathering to complete so the SDP includes candidates
    await new Promise((resolve) => {
      if (pc.iceGatheringState === "complete") {
        resolve();
      } else {
        const handler = () => {
          if (pc.iceGatheringState === "complete") {
            pc.onicegatheringstatechange = null;
            resolve();
          }
        };
        pc.onicegatheringstatechange = handler;
        // also add a safety timeout in case ICE never finishes (optional)
        setTimeout(() => {
          console.warn("ICE gathering timeout; proceeding with current SDP");
          resolve();
        }, 5000);
      }
    });

    console.log("FINAL LOCAL SDP (with candidates if any):\n", pc.localDescription.sdp);

    // 6) Send the offer (including ICE) to your server's /offer endpoint
    const resp = await fetch("/offer", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        sdp: pc.localDescription.sdp,
        type: pc.localDescription.type,
        client_id
      })
    });

    if (!resp.ok) {
      const text = await resp.text();
      throw new Error("Server /offer failed: " + resp.status + " " + resp.statusText + "\n" + text);
    }

    const answer = await resp.json();
    console.log("Received answer from server:", answer.type);

    // 7) Apply remote description (server answer)
    await pc.setRemoteDescription(answer);
    console.log("Remote description set. Waiting for remote tracks...");

  } catch (err) {
    console.error("Error in WebRTC setup:", err);
    alert("WebRTC error (see console).");
  }
})();
</script>--><!--

  <script>
    async function getDevices() {
      if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
        console.error("Media Devices API not supported.");
        return [];
      }

      const devices = await navigator.mediaDevices.enumerateDevices();
      devices.forEach(d => console.log(d.kind, d.label, d.deviceId));
      return devices;
    }

    async function startWebRTC() {
      const devices = await getDevices();

      const videoDevice = devices.find(d => d.kind === "videoinput");
      const audioDevice = devices.find(d => d.kind === "audioinput");

      if (!videoDevice && !audioDevice) {
        console.error("No camera or microphone found.");
        return;
      }

      const constraints = {
        video: videoDevice ? { deviceId: videoDevice.deviceId } : false,
        audio: audioDevice ? { deviceId: audioDevice.deviceId } : false
      };

      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        document.getElementById("local").srcObject = stream;

        function uuidv4() {
          return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
            let r = Math.random() * 16 | 0, v = c === 'x' ? r : (r & 0x3 | 0x8);
            return v.toString(16);
          });
        }

        let client_id = uuidv4();

        // Create peer connection
        const pc = new RTCPeerConnection();

        // Add local tracks
        stream.getTracks().forEach(track => pc.addTrack(track, stream));

        // Show remote tracks
        pc.ontrack = e => {
          document.getElementById("remote").srcObject = e.streams[0];
        };

        // Create offer
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        // Send offer to server
        const resp = await fetch("/offer", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            sdp: pc.localDescription.sdp,
            type: pc.localDescription.type
          })
        });

        const answer = await resp.json();
        await pc.setRemoteDescription(answer);

      } catch (err) {
        console.error("Error accessing media devices:", err);
      }
    }

    startWebRTC();
  </script>

</body>
</html>
-->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Real-Time Language Translation</title>
  <style>
    video { width: 45%; margin: 5px; background: black; }
  </style>
</head>
<body>
  <h2>Real-Time Language Translator</h2>
  <video id="video" autoplay playsinline></video>
  <form action="{{ url_for('set_lang') }}" method="post">
    <label for="og_language">Choose the language you want to speak in:</label>
    <select name="og_language" id="og_language">
      <option value="en">English</option>
      <option value="fr">French</option>
      <option value="hi">Hindi</option>
      <option value="zh">Mandarin Chinese</option>
      <option value="ja">Japanese</option>
      <option value="pt">Portuguese</option>
      <option value="it">Italian</option>
    </select>
  </form>
  <form action="{{ url_for('set_lang') }}" method="post">
    <label for="translated_language">Choose the language you want your speech translated to:</label>
    <select name="translated_language" id="translated_language">
      <option value="en">English</option>
      <option value="fr">French</option>
      <option value="hi">Hindi</option>
      <option value="zh">Mandarin Chinese</option>
      <option value="ja">Japanese</option>
      <option value="pt">Portuguese</option>
      <option value="it">Italian</option>
    </select>
  </form>

  <script>
    async function start() {
      const video = document.getElementById("video");
      let mediaRecorder;
      const socket = new WebSocket('ws://localhost:5000/ws');

      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      video.srcObject = stream;
      mediaRecorder = new MediaRecorder(stream);

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
            socket.send(event.data);
        }
      };
      mediaRecorder.start(100);
    }
    start();
  </script>
</body>
</html>
